서버 스펙이 고성능이기 때문에, 하나의 물리적 서버에서 여러 개의 가상 서버를 실행하여 로드 밸런싱 실습을 할 수 있다



----
실전 지식
	: Spring Data JPA 는 db와의 연동을 전제로 하기 때문에, db 관련 depency 가 없으면 걍 애플리케이션 실행이 안된다
	: application.yml 에 여러 서버에 대해 정의를 했는데 프로파일설정? 그런걸 해줬다
		: https://lucas-owner.tistory.com/22
----

Reverse Proxy 와 Forward Proxy
	: Reverse Proxy 는 reverse response type ,  Forward Proxy는 front response type 라고도 한다
	: 프록시Proxy >> 대리인. 중간에 낑기는 얘
		: 종류 << 네트워크 상 어디에 위치하느냐, 혹은 어느 방향으로 데이터를 제공하느냐에 따라 갈린다
			1. Forward Proxy >>클라이언트 쪽에 위치하여, 클라이언트 대신 프록시 서버가 대상 서버에 전달해주는 방식
				: 대개 프록시라 하면 포워드 프록시
				: 목적 >> 보안 강화, 캐싱(속도 향상)

			2. Reverse Proxy >> web server 쪽에 위치하여 클라이언트의 요청을 특정 서버에 배분해주는 방식 
				: 그러니까 로드 밸런싱 해준다.

	: https://inpa.tistory.com/entry/NETWORK-%F0%9F%93%A1-Reverse-Proxy-Forward-Proxy-%EC%A0%95%EC%9D%98-%EC%B0%A8%EC%9D%B4-%EC%A0%95%EB%A6%AC


-----
Nginx를 사용한 로드밸런싱 환경 구축
	: 절차1	
		1. 스프링부트 프로젝트 생성 - 컨트롤러 정도만 구현
		2. 프로젝트 빌드
			: 해당 프로젝트의 루트 경로에서 CMD 열고 gradlew.bat bootJar 실행
			: 빌드된 프로젝트 파일은 
				: /build/libs 에서 확인 가능
				: java -jar 빌드파일명.jar 명령어를 입력하여 실행 가능
		3. 서버에 파일이 저장될 환경 구성
			(1) 디렉터리 생성>> sudo mkdir -p /var/www/myapp/deployments/v1.0.0/
			(2) 폴더 권한부여>> sudo chmod 755 /var/www/myapp/deployments/v1.0.0/
			(3) 폴더 소유자 변경>> sudo chown -R user:user /var/www/myapp/deployments/v1.0.0/



		4. 서버로 빌드된 jar 파일을 전송 >>  scp 로컬파일명.jar 서버상의사용자명@서버IP주소:/서버상에저장될경로/저장될파일명T.jar
`			: 다음을 입력했음>> scp loadbalancingtest01-0.0.1-SNAPSHOT.jar user@202.31.200.130:/var/www/myapp/deployments/v1.0.0/loadbalancingtest01-0.0.1-SNAPSHOT.jar

		5.서버에서 실행해보기
			(0) 서버의 자바 업데이트
				: java11 이라서 java21 로 업뎃해줌
					0. sudo apt-get update
					1. sudo apt-get install openjdk-21-jdk
					2. sudo update-alternatives --config java 하고 21을 기본으로 설정
					3. 환경 변수 설정 >> 
						(1) export JAVA_HOME=/usr/lib/jvm/java-21-openjdk-amd64
						(2) export PATH=$JAVA_HOME/bin:$PATH

			(1) 특정 프로파일(server1)로 스프링부트 애플리케이션 시작하기 >>   java -jar -Dspring.profiles.active=프로파일 {파일명}.jar
				: 다음을 입력했음>>java -jar -Dspring.profiles.active=server1 loadbalancingtest01-0.0.1-SNAPSHOT.jar

		: https://hudi.blog/load-balancing-with-nginx/

	: 절차2
		1. nginx 설치 
			: https://velog.io/@xangj0ng/Linux-Ubuntu-Nginx-%EC%84%A4%EC%B9%98
			(1) sudo apt update
			(1) sudo apt upgrade
			(2) sudo apt install nginx

		2. nginx 서버 설정 변경 >> 
			(1) sudo vim /etc/nginx/conf.d 에 default.conf 생성 및 다음 내용을 작성
upstream samplecluster {
  server localhost:8801; 
  server localhost:8802;
  server localhost:8803;
}

server {
  listen 8800;

  location / {
    proxy_pass http://samplecluster;
  }
}

			(2) sudo nginx -s reload

		3. 접속해보기 >> http://202.31.200.130:8800
			: server-1, server-2 , server-3 을 빙글빙글 돌아가면서 잘 실행됨을 확인 가능

		4. 접속 로그 확인 >>sudo tail -f /var/log/nginx/access.log

	

	: 효과. 효율성. 딜레이




-----

Apache Jmeter 사용법
    : 유튜브 생활코딩 참고
    : 초기 설정
	0. JDK 다운로드 및 환경변수 설정
		: 기본적으로 Jmeter 가 자바 기반이라 깔려있어야된다
		: https://hongong.hanbit.co.kr/java-%EC%9E%90%EB%B0%94-%EA%B0%9C%EB%B0%9C-%EB%8F%84%EA%B5%AC-%EC%84%A4%EC%B9%98-oracle-jdk-21/
			: 근데 위 사이트에서 환경 변수 설정 중 JAVA_HOME 을 C:\Program Files\Java 까지만 설정해놨는데, 실제로는 C:\Program Files\Java\jdk-21 까지 해놔야된다
	1. https://jmeter.apache.org/download_jmeter.cgi 에서 다운 및 압축 해제
	2. bin 디렉터리 의 ApacheJemeter.jar 클릭 시 사용 가능

    : 활용
	(1) test plan 테스트 계획 작성을 하고 접속하기
	    1. 스레드 그룹 생성
		: 테스트 계획 우클릭-add(추가)-thread(스레드)-thread group(스레드그룹) 택 
			: Number of threads 쓰레드들의 수 >> 몇 유저가 접속을 할 것인가
				: 그러니까 10으로 하면 10명의 사용자가 접속하는 것 

			: Loop count 루프 카운트 >> 한 유저가 몇번 접속을 할 것인가
				: 그러니까 10으로 하면 한 사용자 당 10 번 접속하는 것 

	    2. 스레드 그룹 활용 - 요청 설정
		(1) 생성한 스레드그룹 우클릭-add(추가)-sampler(표본추출기)-http reqest(http 요청) 택 
			: sampler 를 통해서 어떤 프로토콜로 접속하게 할 건지 설정 가능
		(2) http requets 설정
		    1. Web server
			: protocol 프로토콜
				: 만약 https 접속의 경우 protocol 란에 https 를 적으면 됨
		 		: http 면 프로토콜란을 걍 비워두면 디폴트값인  http 적용됨
			: server name or IP >> 접속하고자 하는 서버의 IP 주소 입력
				: 202.31.200.130 입력함
			: 포트 번호 port number >> 접속하고자 하는 포트 번호 입렫ㄱ
				: 8800 입력
`				: 디폴트는 80 값

		    2. Http request
			: GET/POST 등의 http method 설정
			: path >> 요청 경로
				: ex) "IP:포트번호/uhahaha" 로의 접속을 원하는 경우 uhahaha 를 작성 (앞에 / 붙이는거 아니다)

		(3) 접속 : 위의 start 버튼(▶) 누르면 됨


	(2) 서버 부하량(얼마나 힘들어하는지) 확인해보기 - 개별적인
	    : 종류
		1. 스레드 그룹에 대한  
		2. 스레드 그룹의 특정 http request 에 대한 >> http request우클릭 - add(추가) - listner(리스너)-view reuslt tree(결과물의 트리 보기) 하고 start 버튼(▶) 누름

	    : 관련 지식
		: request 의 status >> 3단계로 구성
		    (1) request start
		    (2) response start 
		    (3) request end
		: latency >> requets start ~response start 
		: Load time >> requets start ~response end (request end 막 시작하는 구간)
			: 일반적으로 performance test 로 성능을 측정할 때는 load time 을 기준으로 하게 된다

	    : 분석
		sampler result (표본추출기결과) 탭 
 			: load time(로드 시간)
			    : 밀리세크(1/1000 초) 단위로 표시됨



	(3) 서버 부하량(얼마나 힘들어하는지) 확인해보기 - 종합적인
	    : 종류
		1. 스레드 그룹에 대한  
		2. 스레드 그룹의 특정 http request 에 대한 >> http request우클릭 - add(추가) - listner(리스너)-summary report (요약보고서) 하고 start 버튼(▶) 누름

	    : 분석
	 	samples(표본수) >> 총 몇번 접속이 됬는가. (=스레드그룹*루프수)
		average (평균) >> 평균 load time
		min (최소값) >> 최소 load time
		max (최대값) >> 최대 load time
		std Dev (표준편차) >> 평균으로 부터 각각의 요청 시간이 얼마나 떨어져있는가. 얼마나 들쑥날쑥한가
			: 클 수록 들쑥날쑥 한것

		Error(오류)>> 에러의 발생률
		throughput(처리량) >> 초당 몇번의 access 가 이뤄졌는가
			: 높을 수록 좋은거임


	(4) 서버 부하량(얼마나 힘들어하는지) 확인해보기 - 그래프로	
	    : 시간적인 것을 확인하고자 할 때 좋다
	    : 종류
		1. 스레드 그룹에 대한  
		2. 스레드 그룹의 특정 http request 에 대한 >> http request우클릭 - add(추가) - listner(리스너)-graph result (결과그래프) 하고 start 버튼(▶) 누름
	    : 분석
		data(데이터)
		average(평균)
		medium(중간값) 
		deviation >> 편차
		throughput(처리량)
		
----

기타 작업 내용
	1. 인텔리제이 커뮤니티 버전 설치함
		: https://velog.io/@bi-sz/IntelliJ-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%84%B1%ED%95%98%EA%B8%B0

----



1. **가상 서버 설정**:
   - **Virtual Machines (VMs)**: 하나의 물리적 서버에서 여러 개의 가상 머신을 생성합니다. 각각의 가상 머신에 웹 서버(예: Nginx, Apache)를 설치합니다.
   - **Docker**: Docker를 사용하여 여러 개의 컨테이너를 생성하고, 각 컨테이너에서 웹 서버를 실행할 수도 있습니다.

   예를 들어, 4개의 가상 머신 또는 Docker 컨테이너를 생성하여 각각의 머신이 동일한 웹 애플리케이션을 호스팅하게 합니다.

2. **로드 밸런서 설정**:
   - Nginx 또는 HAProxy를 사용하여 로드 밸런서를 설정합니다.
   - **Reverse Response Type**: 로드 밸런서가 클라이언트 요청을 받아 적절한 서버로 요청을 전달하고, 해당 서버에서 응답을 받아 다시 클라이언트에게 전달하도록 설정합니다.
   - **Front Response Type**: 로드 밸런서가 클라이언트에게 가장 가까운 서버로 직접 요청을 보내도록 설정합니다.

### 2. JMeter 설정 및 테스트 계획 작성

1. **JMeter 설치**:
   - 서버에 JMeter를 설치합니다.
   - 설치된 JMeter를 통해 클라이언트의 역할을 수행하며 트래픽을 생성합니다.

2. **테스트 계획 작성**:
   - **Thread Group**: 사용자 수와 반복 횟수를 설정합니다. 예를 들어, 100명의 사용자가 1000번의 요청을 보낸다고 설정할 수 있습니다.
   - **HTTP Request Sampler**: 로드 밸런서의 IP 주소와 포트를 사용하여 요청을 보냅니다. 이때, Reverse Response Type과 Front Response Type 각각의 설정에 대한 HTTP 요청을 작성합니다.
   - **Listeners**: 응답 시간을 측정할 수 있는 `View Results in Table`, `Summary Report` 등을 추가합니다.

### 3. 테스트 실행 및 데이터 수집

1. **Reverse Response Type 테스트**:
   - JMeter에서 Reverse Response Type 로드 밸런서 설정에 따라 트래픽을 생성합니다.
   - 모든 응답 시간, 처리량, 에러율 등을 기록합니다.

2. **Front Response Type 테스트**:
   - 동일한 방식으로 Front Response Type 설정에 대해 테스트를 진행합니다.
   - 마찬가지로 응답 시간, 처리량, 에러율 등의 데이터를 수집합니다.

### 4. 결과 분석

1. **응답 시간 분석**:
   - 두 방식의 평균 응답 시간을 비교합니다.
   - 최대 응답 시간과 최소 응답 시간을 확인하여 성능의 일관성을 평가합니다.

2. **처리량 분석**:
   - 초당 처리할 수 있는 요청 수를 비교하여 두 방식 중 어느 것이 더 효율적인지 확인합니다.

3. **에러율 분석**:
   - 각 방식에서 발생한 에러의 비율을 분석하여 안정성을 평가합니다.

### 5. 결론 도출 및 보고서 작성

1. **결론 도출**:
   - 두 가지 로드 밸런싱 방식 중 어떤 방식이 더 나은 성능을 제공하는지 결론을 도출합니다.
   - 다양한 트래픽 시나리오에서의 성능 차이를 분석합니다.

2. **보고서 작성**:
   - JMeter에서 수집한 데이터를 바탕으로 보고서를 작성합니다.
   - 그래프와 표를 활용하여 결과를 시각적으로 표현합니다.

이 실습 절차를 통해 주어진 서버에서 다양한 로드 밸런싱 시나리오를 평가할 수 있습니다.
